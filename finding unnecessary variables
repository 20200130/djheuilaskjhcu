### 67번째줄 경로
### 69번째줄 경로 두개는 바꿔주셔야합니다. spyder로 돌렸습니다.
### 모듈 불러오기
import os
import pandas as pd 
import numpy as np
from multiprocessing import Pool 
import multiprocessing
from data_loader import data_loader #data_loader.py 파일을 다운 받아 주셔야 합니다. 
from tqdm import tqdm
from functools import partial

### 함수 선언
def data_loader_all(func, path, train, nrows, **kwargs):
    '''
    Parameters:
    
    func: 하나의 csv파일을 읽는 함수 
    path: [str] train용 또는 test용 csv 파일들이 저장되어 있는 폴더 
    train: [boolean] train용 파일들 불러올 시 True, 아니면 False
    nrows: [int] csv 파일에서 불러올 상위 n개의 row 
    lookup_table: [pd.DataFrame] train_label.csv 파일을 저장한 변수 
    event_time: [int] 상태_B 발생 시간 
    normal: [int] 상태_A의 라벨
    
    Return:
    
    combined_df: 병합된 train 또는 test data
    '''
    
    # 읽어올 파일들만 경로 저장 해놓기 
    files_in_dir = os.listdir(path)
    
    files_path = [path+'/'+file for file in files_in_dir]
    
    if train :
        func_fixed = partial(func, nrows = nrows, train = True, lookup_table = kwargs['lookup_table'], event_time = kwargs['event_time'], normal = kwargs['normal'])
        
    else : 
        func_fixed = partial(func, nrows = nrows, train = False)
    
    
    # 여러개의 코어를 활용하여 데이터 읽기 
    if __name__ == '__main__':
        pool = Pool(processes = multiprocessing.cpu_count()) 
        df_list = list(tqdm(pool.imap(func_fixed, files_path), total = len(files_path)))
        pool.close()
        pool.join()
    
    # 데이터 병합하기 
    combined_df = pd.concat(df_list, ignore_index=True)
    
    return combined_df

### 원본 경로 코드
'''    
train_path = 'c:/users/호연씨/.spyder-py3/wonza/train'
test_path = 'c:/users/호연씨/.spyder-py3/wonza/test'
label = pd.read_csv('c:/users/호연씨/.spyder-py3/wonza/train_label.csv')

train = data_loader_all(data_loader, path = train_path, train = True, nrows = 100, normal = 999, event_time = 10, lookup_table = label)

test = data_loader_all(data_loader, path = test_path, train = False, nrows = 60)
'''

### csv를 30개만 불러오기 위한 새로운 경로 설정
train_path = 'c:/users/호연씨/.spyder-py3/wonza/1'  # 1이란 폴더에 0.csv~29.csv를 읽어오기

label = pd.read_csv('c:/users/호연씨/.spyder-py3/wonza/train_label.csv')  # 라벨 읽어오기


### 설정한 경로의 파일을 로더함수로 불러오기
train1 = data_loader_all(data_loader, path = train_path, train = True, nrows = 100, normal = 999, event_time = 10, lookup_table = label)

    
### 어레이로 변환
train = np.array(train1)


'''
### 미완성 문자열 변수 찾기 
count_box = np.zeros((10000,2))  # 문자열 변수를 저장할 빈 공간
x = 0                            # 반복문 카운터

for i in range(0,30):
    for j in range(0,5121):        
        if type(train[i*100][j+2]) == str :
            count_box[x][0] = i             # 0열에는 csv 번호를 
            count_box[x][1] = j             # 1열에는 문자열 변수를 
            x = x + 1                       # 추가 될때만 다음 행으로 넘어감
            
                                            ### 찾은 문자열 변수들을 새로운 변수로 저장
                                            
                                            
                                            
                                            
va_stack = np.zeros((1026,1))
for x in range(0,1026):
    va_stack[x] = count_box[x][1]

'''



### 분산이 0인 변수 찾기
var_zero = np.zeros((30,5121))  # 30행 = csv30개 / 5121열 = 변수5121개를 위한 빈 어레이 생성

for i in range(0,30):   # 행별로 분산이 0인 변수를 저장  왜냐하면 각 csv파일별 분산이 0인 변수가 상이하기 때문  
    x = 0    # <--- var_zero에 차곡차곡 쌓기위한 카운터 변수
    for j in range(0,5121):
        #mean_box[i,j] = np.var(train[100*i:100*(i+1),j+2]) 
        if np.var(train[100*i:100*(i+1),j+2]) == 0 :
            var_zero[i][x] = j
            x = x + 1

var_zero = var_zero.astype('int32') # 데이터타입을 int32로 전환

### 교집합 구해주는 함수 --- 모든 파일에서 분산이 0인 변수를 찾기위해서
def intersection(array): # 교집합 연산을 위해 set으로 형변환
    ''' 
    ---PARAMETER---
    array : 각 행의 교집합을 구할 2차원 np.array 
    '''
    print(array[0][0])
    set1 = set(array[0])                   # 첫 행을 반복문 전에 미리 저장
    for x in range(1,30):       
        set1 = set1 & set(array[x])   # 다음 행과 교집합 연산 ---(반복)
    return set1                       # 2차원 배열 array의 교집합을 반환
        


remove_list_1 = list(intersection(var_zero))  # 교집합을 변수에 저장 
remove_list_1.remove(0)                       # var_zero의 빈공간을 의미하던 0을 지워줌 

remove_list = []   # 분산이 0이고 평균도 0인 최종 제거변수리스트 

for each in remove_list_1:
    new = []                # 반복될 때마다 초기화될 임시 리스트
    for i in range(0,30):   # 한 변수의 파일별 평균을 집합으로 만들어 주는 부분
        new.append(np.mean(train[100*i:100*(i+1),each]))
    if len(set(new)) == 1 : # 집합의 원소가 하나라면 모든 평균은 같다는 말 --> remove_list에 추가
        remove_list.append(each) 
        
print("분산이 0인 변수의 수 : ", len(remove_list_1), "개")
print("분산이 0이고 평균이 모두같은 변수 : ", len(remove_list), "개")

